<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <artifactId>kshfx-parent</artifactId>
        <groupId>com.sinobest.kshfx</groupId>
        <version>0.1.0</version>
        <relativePath>../pom.xml</relativePath>
    </parent>
    <artifactId>kshfx-spark</artifactId>
    <!-- 打成jar包 -->
    <!--<packaging>jar</packaging>-->

    <name>kshfx-spark_${project.version}</name>
    <url>http://maven.apache.org</url>

    <properties>
        <!--  chd5.7.1 spark 1.6 -->
        <!-- <scala.binary.version>2.10</scala.binary.version>
         <scala.version>2.10.6</scala.version>
         <spark-scala-version>2.10</spark-scala-version>
         <maven-shade-version>2.3</maven-shade-version>
         <commons.io.version>2.4</commons.io.version>
         <commons.lang3.version>3.3.2</commons.lang3.version>
         -->

        <!--  spark 2.2 -->
        <scala.binary.version>2.11</scala.binary.version>
        <scala.version>2.11.8</scala.version>
        <spark-scala-version>2.11</spark-scala-version> <!-- spark-scala -->
        <maven-shade-version>2.3</maven-shade-version>
        <commons.io.version>2.4</commons.io.version>
        <commons.lang3.version>3.3.2</commons.lang3.version>

    </properties>

    <build>
        <finalName>kshfx-spark</finalName>
        <plugins>
            <!-- build scala -->
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>3.2.2</version>
                <configuration>
                    <encoding>UTF-8</encoding>
                    <scalaCompatVersion>${scala.binary.version}</scalaCompatVersion>
                    <scalaVersion>${scala.version}</scalaVersion>
                    <recompileMode>incremental</recompileMode>
                    <useZincServer>true</useZincServer>
                    <args>
                        <arg>-unchecked</arg>
                        <arg>-deprecation</arg>
                        <arg>-feature</arg>
                    </args>
                    <javacArgs>
                        <javacArg>-source</javacArg>
                        <javacArg>${java.version}</javacArg>
                        <javacArg>-target</javacArg>
                        <javacArg>${java.version}</javacArg>
                    </javacArgs>
                </configuration>
                <executions>
                    <execution>
                        <id>eclipse-add-source</id>
                        <goals>
                            <goal>add-source</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>scala-test-compile-first</id>
                        <phase>process-test-resources</phase>
                        <goals>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>attach-scaladocs</id>
                        <phase>verify</phase>
                        <goals>
                            <goal>doc-jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

    <dependencies>
        <dependency>
            <groupId>com.sinobest.kshfx</groupId>
            <artifactId>kshfx-mapreduce</artifactId>
            <version>${project.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>javax.servlet</groupId>
                    <artifactId>servlet-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>commons-io</groupId>
                    <artifactId>commons-io</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- 引入对scala SDK的依赖-->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
        </dependency>
        <!-- scala-actors -->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-actors</artifactId>
            <version>2.10.4</version>
        </dependency>
        <!-- spark 依赖开始 -->
        <dependency>
            <groupId>org.jetbrains</groupId>
            <artifactId>annotations</artifactId>
            <version>RELEASE</version>
        </dependency>
        <!-- 解决Spark应用程序读取HDFS文件，引入的HBase和Hadoop的Jar包冲突问题 -->
        <dependency>
            <groupId>commons-io</groupId>
            <artifactId>commons-io</artifactId>
            <version>${commons.io.version}</version>
        </dependency>
        <!-- spark core -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.scala-lang</groupId>
                    <artifactId>scala-reflect</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- spark sql -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <!-- spark hive -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <!-- spark streaming -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <!-- spark streaming-flume -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-flume_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>javax.servlet</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- SparkStreaming的Flume的Pull的方式的依赖的3个包-->
        <!-- 此3个包必须放在Flume的运行的lib下面，如果已经存在就没必要添加，官方文档说明：
        Sink JARs: Add the following JARs to Flume’s classpath (see Flume’s documentation to see how) in the machine designated to run the custom sink .-->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-flume-sink_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
            <version>${commons.lang3.version}</version>
        </dependency>
        <!-- SparkStreaming for Kafka -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-kafka-0-8_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <artifactId>metrics-core</artifactId>
                    <groupId>com.yammer.metrics</groupId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- spark-graphx -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-graphx_${spark-scala-version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.scala-lang</groupId>
                    <artifactId>scala-reflect</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
    </dependencies>

    <!-- dependencyManagement的作用其实相当于一个对所依赖jar包进行版本管理的管理器.只是对版本进行管理，不会实际引入jar  -->
    <!--<dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.mortbay.jetty</groupId>
                <artifactId>servlet-api-2.5</artifactId>
                <version>6.1.14</version>
            </dependency>
        </dependencies>
    </dependencyManagement>-->

    <!--<repositories>
        <repository>
            <id>maven-local</id>
            <url>D:\libs\maven\</url>
        </repository>
    </repositories>-->
</project>